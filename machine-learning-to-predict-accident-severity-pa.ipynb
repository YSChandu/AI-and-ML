{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yHIGtNM-x6Ka",
    "outputId": "c9725dc9-3d80-4817-fac3-b5f5f2febe13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 46 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   ID                     object \n",
      " 1   Source                 object \n",
      " 2   Severity               int64  \n",
      " 3   Start_Time             object \n",
      " 4   End_Time               object \n",
      " 5   Start_Lat              float64\n",
      " 6   Start_Lng              float64\n",
      " 7   End_Lat                float64\n",
      " 8   End_Lng                float64\n",
      " 9   Distance(mi)           float64\n",
      " 10  Description            object \n",
      " 11  Street                 object \n",
      " 12  City                   object \n",
      " 13  County                 object \n",
      " 14  State                  object \n",
      " 15  Zipcode                object \n",
      " 16  Country                object \n",
      " 17  Timezone               object \n",
      " 18  Airport_Code           object \n",
      " 19  Weather_Timestamp      object \n",
      " 20  Temperature(F)         float64\n",
      " 21  Wind_Chill(F)          float64\n",
      " 22  Humidity(%)            float64\n",
      " 23  Pressure(in)           float64\n",
      " 24  Visibility(mi)         float64\n",
      " 25  Wind_Direction         object \n",
      " 26  Wind_Speed(mph)        float64\n",
      " 27  Precipitation(in)      float64\n",
      " 28  Weather_Condition      object \n",
      " 29  Amenity                bool   \n",
      " 30  Bump                   bool   \n",
      " 31  Crossing               bool   \n",
      " 32  Give_Way               bool   \n",
      " 33  Junction               bool   \n",
      " 34  No_Exit                bool   \n",
      " 35  Railway                bool   \n",
      " 36  Roundabout             bool   \n",
      " 37  Station                bool   \n",
      " 38  Stop                   bool   \n",
      " 39  Traffic_Calming        bool   \n",
      " 40  Traffic_Signal         bool   \n",
      " 41  Turning_Loop           bool   \n",
      " 42  Sunrise_Sunset         object \n",
      " 43  Civil_Twilight         object \n",
      " 44  Nautical_Twilight      object \n",
      " 45  Astronomical_Twilight  object \n",
      "dtypes: bool(13), float64(12), int64(1), object(20)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "df = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\US Accidents Dataset\\US_Accidents_March23.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOANP6mux6Kb"
   },
   "source": [
    "### Step 3. Extract year, month, day, hour, weekday, and time to clear accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FZwTKG1Dx6Kb",
    "outputId": "583b9fc2-7de8-4b7b-daea-931f0712d65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 52 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   ID                     object        \n",
      " 1   Source                 object        \n",
      " 2   Severity               int64         \n",
      " 3   Start_Time             datetime64[ns]\n",
      " 4   End_Time               datetime64[ns]\n",
      " 5   Start_Lat              float64       \n",
      " 6   Start_Lng              float64       \n",
      " 7   End_Lat                float64       \n",
      " 8   End_Lng                float64       \n",
      " 9   Distance(mi)           float64       \n",
      " 10  Description            object        \n",
      " 11  Street                 object        \n",
      " 12  City                   object        \n",
      " 13  County                 object        \n",
      " 14  State                  object        \n",
      " 15  Zipcode                object        \n",
      " 16  Country                object        \n",
      " 17  Timezone               object        \n",
      " 18  Airport_Code           object        \n",
      " 19  Weather_Timestamp      object        \n",
      " 20  Temperature(F)         float64       \n",
      " 21  Wind_Chill(F)          float64       \n",
      " 22  Humidity(%)            float64       \n",
      " 23  Pressure(in)           float64       \n",
      " 24  Visibility(mi)         float64       \n",
      " 25  Wind_Direction         object        \n",
      " 26  Wind_Speed(mph)        float64       \n",
      " 27  Precipitation(in)      float64       \n",
      " 28  Weather_Condition      object        \n",
      " 29  Amenity                bool          \n",
      " 30  Bump                   bool          \n",
      " 31  Crossing               bool          \n",
      " 32  Give_Way               bool          \n",
      " 33  Junction               bool          \n",
      " 34  No_Exit                bool          \n",
      " 35  Railway                bool          \n",
      " 36  Roundabout             bool          \n",
      " 37  Station                bool          \n",
      " 38  Stop                   bool          \n",
      " 39  Traffic_Calming        bool          \n",
      " 40  Traffic_Signal         bool          \n",
      " 41  Turning_Loop           bool          \n",
      " 42  Sunrise_Sunset         object        \n",
      " 43  Civil_Twilight         object        \n",
      " 44  Nautical_Twilight      object        \n",
      " 45  Astronomical_Twilight  object        \n",
      " 46  Year                   int64         \n",
      " 47  Month                  object        \n",
      " 48  Day                    int64         \n",
      " 49  Hour                   int64         \n",
      " 50  Weekday                object        \n",
      " 51  Time_Duration(min)     float64       \n",
      "dtypes: bool(13), datetime64[ns](2), float64(13), int64(4), object(20)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Convert Start_Time and End_Time to datetypes\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')\n",
    "\n",
    "# Extract year, month, day, hour and weekday\n",
    "df['Year']=df['Start_Time'].dt.year\n",
    "df['Month']=df['Start_Time'].dt.strftime('%b')\n",
    "df['Day']=df['Start_Time'].dt.day\n",
    "df['Hour']=df['Start_Time'].dt.hour\n",
    "df['Weekday']=df['Start_Time'].dt.strftime('%a')\n",
    "\n",
    "# Extract the amount of time in the unit of minutes for each accident, round to the nearest integer\n",
    "td='Time_Duration(min)'\n",
    "df[td]=round((df['End_Time']-df['Start_Time'])/np.timedelta64(1,'m'))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LJ8uJFNx6Kc"
   },
   "source": [
    "### Step 4. Deal with outliers\n",
    "\n",
    "#### A. Drop rows with negative time_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1yWtuSM7x6Kd",
    "outputId": "99d10371-6207-4b67-abab-f017c2f22d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Time_Duration(min), dtype: float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any negative time_duration values\n",
    "df[td][df[td]<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vyO1ADfWx6Ke",
    "outputId": "5240a957-778c-4301-92df-59656007b2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 52 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   ID                     object        \n",
      " 1   Source                 object        \n",
      " 2   Severity               float64       \n",
      " 3   Start_Time             datetime64[ns]\n",
      " 4   End_Time               datetime64[ns]\n",
      " 5   Start_Lat              float64       \n",
      " 6   Start_Lng              float64       \n",
      " 7   End_Lat                float64       \n",
      " 8   End_Lng                float64       \n",
      " 9   Distance(mi)           float64       \n",
      " 10  Description            object        \n",
      " 11  Street                 object        \n",
      " 12  City                   object        \n",
      " 13  County                 object        \n",
      " 14  State                  object        \n",
      " 15  Zipcode                object        \n",
      " 16  Country                object        \n",
      " 17  Timezone               object        \n",
      " 18  Airport_Code           object        \n",
      " 19  Weather_Timestamp      object        \n",
      " 20  Temperature(F)         float64       \n",
      " 21  Wind_Chill(F)          float64       \n",
      " 22  Humidity(%)            float64       \n",
      " 23  Pressure(in)           float64       \n",
      " 24  Visibility(mi)         float64       \n",
      " 25  Wind_Direction         object        \n",
      " 26  Wind_Speed(mph)        float64       \n",
      " 27  Precipitation(in)      float64       \n",
      " 28  Weather_Condition      object        \n",
      " 29  Amenity                object        \n",
      " 30  Bump                   object        \n",
      " 31  Crossing               object        \n",
      " 32  Give_Way               object        \n",
      " 33  Junction               object        \n",
      " 34  No_Exit                object        \n",
      " 35  Railway                object        \n",
      " 36  Roundabout             object        \n",
      " 37  Station                object        \n",
      " 38  Stop                   object        \n",
      " 39  Traffic_Calming        object        \n",
      " 40  Traffic_Signal         object        \n",
      " 41  Turning_Loop           object        \n",
      " 42  Sunrise_Sunset         object        \n",
      " 43  Civil_Twilight         object        \n",
      " 44  Nautical_Twilight      object        \n",
      " 45  Astronomical_Twilight  object        \n",
      " 46  Year                   float64       \n",
      " 47  Month                  object        \n",
      " 48  Day                    float64       \n",
      " 49  Hour                   float64       \n",
      " 50  Weekday                object        \n",
      " 51  Time_Duration(min)     float64       \n",
      "dtypes: datetime64[ns](2), float64(17), object(33)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with td<0\n",
    "\n",
    "neg_outliers=df[td]<=0\n",
    "\n",
    "# Set outliers to NAN\n",
    "df[neg_outliers] = np.nan\n",
    "\n",
    "# Drop rows with negative td\n",
    "df.dropna(subset=[td],axis=0,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-tlqOD3Qx6Kf",
    "outputId": "5fc9224b-0a7f-4c9b-8870-0875431f94b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Time_Duration(min), dtype: float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure no more negative td\n",
    "df[td][df[td]<=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf26tpOAx6Kf"
   },
   "source": [
    "### Step 4. Deal with outliers\n",
    "\n",
    "#### B. Fill outliers with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3t4V5tbCx6Kg",
    "outputId": "ef7b65df-74ee-46de-96f0-58f492fa4efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 52 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   ID                     object        \n",
      " 1   Source                 object        \n",
      " 2   Severity               float64       \n",
      " 3   Start_Time             datetime64[ns]\n",
      " 4   End_Time               datetime64[ns]\n",
      " 5   Start_Lat              float64       \n",
      " 6   Start_Lng              float64       \n",
      " 7   End_Lat                float64       \n",
      " 8   End_Lng                float64       \n",
      " 9   Distance(mi)           float64       \n",
      " 10  Description            object        \n",
      " 11  Street                 object        \n",
      " 12  City                   object        \n",
      " 13  County                 object        \n",
      " 14  State                  object        \n",
      " 15  Zipcode                object        \n",
      " 16  Country                object        \n",
      " 17  Timezone               object        \n",
      " 18  Airport_Code           object        \n",
      " 19  Weather_Timestamp      object        \n",
      " 20  Temperature(F)         float64       \n",
      " 21  Wind_Chill(F)          float64       \n",
      " 22  Humidity(%)            float64       \n",
      " 23  Pressure(in)           float64       \n",
      " 24  Visibility(mi)         float64       \n",
      " 25  Wind_Direction         object        \n",
      " 26  Wind_Speed(mph)        float64       \n",
      " 27  Precipitation(in)      float64       \n",
      " 28  Weather_Condition      object        \n",
      " 29  Amenity                object        \n",
      " 30  Bump                   object        \n",
      " 31  Crossing               object        \n",
      " 32  Give_Way               object        \n",
      " 33  Junction               object        \n",
      " 34  No_Exit                object        \n",
      " 35  Railway                object        \n",
      " 36  Roundabout             object        \n",
      " 37  Station                object        \n",
      " 38  Stop                   object        \n",
      " 39  Traffic_Calming        object        \n",
      " 40  Traffic_Signal         object        \n",
      " 41  Turning_Loop           object        \n",
      " 42  Sunrise_Sunset         object        \n",
      " 43  Civil_Twilight         object        \n",
      " 44  Nautical_Twilight      object        \n",
      " 45  Astronomical_Twilight  object        \n",
      " 46  Year                   float64       \n",
      " 47  Month                  object        \n",
      " 48  Day                    float64       \n",
      " 49  Hour                   float64       \n",
      " 50  Weekday                object        \n",
      " 51  Time_Duration(min)     float64       \n",
      "dtypes: datetime64[ns](2), float64(17), object(33)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers for Time_Duration(min): n * standard_deviation (n=3), backfill with median\n",
    "\n",
    "n=3\n",
    "\n",
    "median = df[td].median()\n",
    "std = df[td].std()\n",
    "outliers = (df[td] - median).abs() > std*n\n",
    "\n",
    "# Set outliers to NAN\n",
    "df[outliers] = np.nan\n",
    "\n",
    "# Fill NAN with median\n",
    "df[td].fillna(median, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "F4DNuDM3x6Kg",
    "outputId": "79463b6d-ff0b-48e9-ffae-8df6d662d190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time to clear an accident: 40560.0 minutes or 676 hours or 28 days; Min to clear an accident td: 1.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Print time_duration information\n",
    "print('Max time to clear an accident: {} minutes or {} hours or {} days; Min to clear an accident td: {} minutes.'.format(df[td].max(),round(df[td].max()/60), round(df[td].max()/60/24), df[td].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TYurod0x6Kh"
   },
   "source": [
    "### Step 5. Select a list of features for machine learning algorithms\n",
    "\n",
    " Only select relavant columns without overwhelming the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pNez2UaXx6Kh"
   },
   "outputs": [],
   "source": [
    "# Set the list of features to include in Machine Learning\n",
    "feature_lst=['Source','TMC','Severity','Start_Lng','Start_Lat','Distance(mi)','Side','City','County','State','Timezone','Temperature(F)','Humidity(%)','Pressure(in)', 'Visibility(mi)', 'Wind_Direction','Weather_Condition','Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop','Sunrise_Sunset','Hour','Weekday', 'Time_Duration(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "smqSv9yOx6Ki",
    "outputId": "7a63f6f6-6588-4e91-dc05-11cd58f9da24"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TMC', 'Side'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select the dataset to include only the selected features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_sel\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_lst\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m df_sel\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TMC', 'Side'] not in index\""
     ]
    }
   ],
   "source": [
    "# Select the dataset to include only the selected features\n",
    "df_sel=df[feature_lst].copy()\n",
    "df_sel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww0GXtRBx6Kj"
   },
   "source": [
    "### Step 6. Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIw4i9DVx6Kj",
    "outputId": "b73a257a-25c2-468d-93e2-5b2028d0baa6"
   },
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df_sel.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBu-aRO3x6Kk",
    "outputId": "27904c8e-1936-4d18-a1b1-79e0ffbf3bdd"
   },
   "outputs": [],
   "source": [
    "df_sel.dropna(subset=df_sel.columns[df_sel.isnull().mean()!=0], how='any', axis=0, inplace=True)\n",
    "df_sel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKNJfpbax6Kl"
   },
   "source": [
    "### Step 7. Select the state of interest: PA\n",
    "\n",
    "\n",
    "Due to the limitation of personal laptop, the whole US dataset is too big to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7JJA2Vhx6Kl",
    "outputId": "f1cc9753-af42-49d1-90b8-4d4fa1c6a102"
   },
   "outputs": [],
   "source": [
    "# Set state\n",
    "state='PA'\n",
    "\n",
    "# Select the state of Pennsylvania\n",
    "df_state=df_sel.loc[df_sel.State==state].copy()\n",
    "df_state.drop('State',axis=1, inplace=True)\n",
    "df_state.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnWkNk4Lx6Kl",
    "outputId": "4f15f698-129d-4245-8023-15fa07d6ed6f"
   },
   "outputs": [],
   "source": [
    "# Map of accidents, color code by county\n",
    "\n",
    "sns.scatterplot(x='Start_Lng', y='Start_Lat', data=df_state, hue='County', legend=False, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIpDUne0x6Km"
   },
   "source": [
    "### Step 8. Deal with categorical data: pd.get_dummies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zjy7pIHDx6Km",
    "outputId": "869354f7-2b2c-42b3-9915-f3b3f7a20ac1"
   },
   "outputs": [],
   "source": [
    "# Generate dummies for categorical data\n",
    "df_state_dummy = pd.get_dummies(df_state,drop_first=True)\n",
    "\n",
    "df_state_dummy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVQ1jWRyx6Kn"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "#### Data preparation: train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRPtcOsmx6Kn"
   },
   "outputs": [],
   "source": [
    "# Assign the data\n",
    "df=df_state_dummy\n",
    "\n",
    "\n",
    "# Set the target for the prediction\n",
    "target='Severity'\n",
    "\n",
    "\n",
    "\n",
    "# Create arrays for the features and the response variable\n",
    "\n",
    "# set X and y\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# Split the data set into training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iy8cyXyx6Kn"
   },
   "outputs": [],
   "source": [
    "# List of classification algorithms\n",
    "algo_lst=['Logistic Regression',' K-Nearest Neighbors','Decision Trees','Random Forest']\n",
    "\n",
    "# Initialize an empty list for the accuracy for each algorithm\n",
    "accuracy_lst=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsVOnwlEx6Kn"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm A. Logistic regression              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axHjjVnjx6Kn",
    "outputId": "93402188-4362-446e-ae34-7cf213772d3b"
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Append to the accuracy list\n",
    "accuracy_lst.append(acc)\n",
    "\n",
    "print(\"[Logistic regression algorithm] accuracy_score: {:.3f}.\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa30Ps8ax6Ko"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm B. The K-Nearest Neighbors (KNN) algorithm\n",
    "   ##### KNN with 6 neighors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIeq_D6nx6Ko",
    "outputId": "70c5e91e-7c5a-46bd-e754-9eb20959c65f"
   },
   "outputs": [],
   "source": [
    "# Create a k-NN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for the training data X\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Append to the accuracy list\n",
    "accuracy_lst.append(acc)\n",
    "\n",
    "print('[K-Nearest Neighbors (KNN)] knn.score: {:.3f}.'.format(knn.score(X_test, y_test)))\n",
    "print('[K-Nearest Neighbors (KNN)] accuracy_score: {:.3f}.'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gHmT6cux6Kp"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm B. The K-Nearest Neighbors (KNN) algorithm\n",
    "   ##### Optmize the number of neighors: plot the accuracy versus number of neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0F0aNrox6Kp"
   },
   "source": [
    "This cell below takes long time to run, so I decided not to run here. Basically it will generate a plot to show the accuracy for each number of neighbors to guide your optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgzL4r2sx6Kp",
    "outputId": "6696ab5c-e6f2-4f79-8ddb-abaf98f650ee"
   },
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(3, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, n_neighbor in enumerate(neighbors):\n",
    "    \n",
    "    # Setup a k-NN Classifier with n_neighbor\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2s-ScGjWx6Kq"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm C. Decision Tree                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSwwqc17x6Kq",
    "outputId": "dc67080a-3fcc-4f44-82aa-140afbcbccde"
   },
   "outputs": [],
   "source": [
    "# Decision tree algorithm\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('[Decision Tree -- entropy] accuracy_score: {:.3f}.'.format(accuracy_entropy))\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate dt_gini, set 'gini' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n",
    "\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_gini = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Append to the accuracy list\n",
    "acc=accuracy_gini\n",
    "accuracy_lst.append(acc)\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('[Decision Tree -- gini] accuracy_score: {:.3f}.'.format(accuracy_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VxHzKH6x6Kq"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm D. Random Forest   \n",
    "   ##### n_estimators=100                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_gCfbSFx6Kq",
    "outputId": "14cb0349-3638-4bee-cfac-aa63026a706f"
   },
   "outputs": [],
   "source": [
    "# Random Forest algorithm\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Append to the accuracy list\n",
    "accuracy_lst.append(acc)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"[Randon forest algorithm] accuracy_score: {:.3f}.\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WErXM87Nx6Kr"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm D. Random Forest   \n",
    "   ##### Visualize important features      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46ZGQK7Qx6Kr",
    "outputId": "cb0495d9-8f5f-4b5c-8674-ebe599a572b6"
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Creating a bar plot, displaying only the top k features\n",
    "k=10\n",
    "sns.barplot(x=feature_imp[:10], y=feature_imp.index[:k])\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKpBNT-Vx6Kr",
    "outputId": "31cda127-fd1f-4809-a3b3-fd6f4cf5020b"
   },
   "outputs": [],
   "source": [
    "# List top k important features\n",
    "k=20\n",
    "feature_imp.sort_values(ascending=False)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szZ6tYcpx6Kr"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n",
    "   #### Algorithm D. Random Forest   \n",
    "   ##### Select the top important features, set the threshold      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3yRpfHgx6Ks",
    "outputId": "8b11f737-6eae-4645-e6e1-95a2efbf625c"
   },
   "outputs": [],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.03\n",
    "sfm = SelectFromModel(clf, threshold=0.03)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "feat_labels=X.columns\n",
    "\n",
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZYzEkLmx6Ks",
    "outputId": "946a0770-bc21-4a9e-c576-519517a8e844"
   },
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tFHUYbmx6Ks",
    "outputId": "da78387f-dd11-4846-fd57-d000b78439cd"
   },
   "outputs": [],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature Model\n",
    "print('[Randon forest algorithm -- Full feature] accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature Model\n",
    "print('[Randon forest algorithm -- Limited feature] accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_important_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiWPrTQyx6Ks"
   },
   "source": [
    "### Step 9. Predict the accident severity with various supervised machine learning algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eU-YPTIyx6Ks",
    "outputId": "f41389c1-c7ef-4f97-bcb6-8f3177c33e4d"
   },
   "outputs": [],
   "source": [
    "# Make a plot of the accuracy scores for different algorithms\n",
    "\n",
    "# Generate a list of ticks for y-axis\n",
    "y_ticks=np.arange(len(algo_lst))\n",
    "\n",
    "# Combine the list of algorithms and list of accuracy scores into a dataframe, sort the value based on accuracy score\n",
    "df_acc=pd.DataFrame(list(zip(algo_lst, accuracy_lst)), columns=['Algorithm','Accuracy_Score']).sort_values(by=['Accuracy_Score'],ascending = True)\n",
    "\n",
    "# Make a plot\n",
    "ax=df_acc.plot.barh('Algorithm', 'Accuracy_Score', align='center',legend=False,color='0.5')\n",
    "\n",
    "# Add the data label on to the plot\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+0.02, i.get_y()+0.2, str(round(i.get_width(),2)), fontsize=10)\n",
    "\n",
    "# Set the limit, lables, ticks and title\n",
    "plt.xlim(0,1.05)\n",
    "plt.xlabel('Accuracy Score')\n",
    "plt.yticks(y_ticks, df_acc['Algorithm'], rotation=0)\n",
    "plt.title('[{}] Which algorithm is better predicting severity?'.format(state))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
